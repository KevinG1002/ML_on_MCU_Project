{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kNnT0e9hWPNE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "import re\n",
    "from hashlib import sha1\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "V8x2P3mCM3yS"
   },
   "outputs": [],
   "source": [
    "MAX_NUM_WAVS_PER_CLASS = 2**27 - 1  # ~134M\n",
    "\n",
    "def which_set(filename, validation_percentage, testing_percentage):\n",
    "    \"\"\"\n",
    "  Helper function when downloading dataset that determines which data partition the file should belong to.\n",
    "\n",
    "  We want to keep files in the same training, validation, or testing sets even\n",
    "  if new ones are added over time. This makes it less likely that testing\n",
    "  samples will accidentally be reused in training when long runs are restarted\n",
    "  for example. To keep this stability, a hash of the filename is taken and used\n",
    "  to determine which set it should belong to. This determination only depends on\n",
    "  the name and the set proportions, so it won't change as other files are added.\n",
    "\n",
    "  It's also useful to associate particular files as related (for example words\n",
    "  spoken by the same person), so anything after '_nohash_' in a filename is\n",
    "  ignored for set determination. This ensures that 'bobby_nohash_0.wav' and\n",
    "  'bobby_nohash_1.wav' are always in the same set, for example.\n",
    "\n",
    "  Args:\n",
    "    filename: File path of the data sample.\n",
    "    validation_percentage: How much of the data set to use for validation.\n",
    "    testing_percentage: How much of the data set to use for testing.\n",
    "\n",
    "  Returns:\n",
    "    String, one of 'training', 'validation', or 'testing'.\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "    base_name = os.path.basename(filename)\n",
    "\n",
    "      # We want to ignore anything after '_nohash_' in the file name when\n",
    "      # deciding which set to put a wav in, so the data set creator has a way of\n",
    "      # grouping wavs that are close variations of each other.\n",
    "\n",
    "    hash_name = re.sub(r'_nohash_.*$', '', base_name).encode('utf-8')\n",
    "\n",
    "      # This looks a bit magical, but we need to decide whether this file should\n",
    "      # go into the training, testing, or validation sets, and we want to keep\n",
    "      # existing files in the same set even if more files are subsequently\n",
    "      # added.\n",
    "      # To do that, we need a stable way of deciding based on just the file name\n",
    "      # itself, so we do a hash of that and then use that to generate a\n",
    "      # probability value that we use to assign it.\n",
    "\n",
    "    hash_name_hashed = hashlib.sha1(hash_name).hexdigest()\n",
    "    percentage_hash = int(hash_name_hashed, 16) % (MAX_NUM_WAVS_PER_CLASS\n",
    "            + 1) * (100.0 / MAX_NUM_WAVS_PER_CLASS)\n",
    "    if percentage_hash < validation_percentage:\n",
    "        result = 'validation'\n",
    "    elif percentage_hash < testing_percentage + validation_percentage:\n",
    "        result = 'testing'\n",
    "    else:\n",
    "        result = 'training'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(dataset_list):\n",
    "    \"\"\"\n",
    "Samples are the files themselves upon which we will apply a feature extraction function.\n",
    "Labels are the parent directories of the file. Thus, this function returns the label of a given wav file. \n",
    "Function takes as input either a text file containing wav file paths OR a list of wav file paths.  \n",
    "    \"\"\"\n",
    "    training_labels = []\n",
    "    if type(dataset_list) == list:\n",
    "        for file in dataset_list:\n",
    "            training_labels.append(os.path.dirname(file))\n",
    "        return np.asarray(training_labels)\n",
    "    \n",
    "    elif os.path.isfile(dataset_list):\n",
    "        with open(dataset_list) as f:\n",
    "            dataset_files = f.readlines()\n",
    "            for file in dataset_files:\n",
    "                training_labels.append(os.path.dirname(file))\n",
    "        return np.asarray(training_labels)\n",
    "    else:\n",
    "        return \"Sorry, wrong input format provided\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nB0i4w6v6Shn"
   },
   "outputs": [],
   "source": [
    "def create_training_txt_file(dataset_path):\n",
    "    \n",
    "    with open(os.path.join(dataset_path, 'testing_list.txt')) as f:\n",
    "        testing_files = f.read().splitlines()\n",
    "\n",
    "\n",
    "    with open(os.path.join(dataset_path, 'validation_list.txt')) as f:\n",
    "        validation_files = f.read().splitlines()\n",
    "        \n",
    "    complete_dataset = []\n",
    "    with open(os.path.join(dataset_path, 'training_list.txt'), \"w\") as train_f:\n",
    "        list_of_local_dirs = [folder for folder in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, folder))]\n",
    "        for folder in list_of_local_dirs:\n",
    "            for file in os.listdir(folder_path):\n",
    "                if which_set(os.path.join(folder,file), 10, 10) == \"training\":\n",
    "                    train_f.write(f\"{os.path.join(folder, file)}\\n\")\n",
    "        \n",
    "                    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_data(training_list_path, training_labels_encoded, testing_list_path, testing_labels_encoded, validation_list_path, validation_labels_encoded):\n",
    "    \n",
    "    size_of_sample_considered = 1 #length of the audio file in seconds\n",
    "    fs = 16000 #the stipulated sampling rate according to the dataset description \n",
    "    segmentLength = 1024 # no. of samples to use per segment window \n",
    "    adjusted_sample_length = int(size_of_sample_considered*fs/segmentLength)*segmentLength # size of audio sample adjusted to be a power of 2. \n",
    "\n",
    "    with open(training_list_path) as f1:\n",
    "        X_training_audio_dataset_paths = f1.read().splitlines()\n",
    "        \n",
    "    with open(testing_list_path) as f2:\n",
    "        X_testing_audio_dataset_paths = f2.read().splitlines()\n",
    "        \n",
    "    with open(validation_list_path) as f3:\n",
    "        X_validation_audio_dataset_paths = f3.read().splitlines()\n",
    "    \n",
    "    \n",
    "    def get_stratified_sample(audio_file_paths, audio_file_labels, fraction):\n",
    "        X_stratified, _, y_stratified, _ = train_test_split(audio_file_paths,audio_file_labels, train_size = fraction, stratify = audio_file_labels)\n",
    "        return X_stratified, y_stratified\n",
    "        \n",
    "    Training_size = 80000\n",
    "    fraction_of_original_size = float(Training_size)/len(X_training_audio_dataset_paths)\n",
    "    \n",
    "    X_training_audio_dataset_paths, y_train = get_stratified_sample(X_training_audio_dataset_paths, training_labels_encoded, fraction_of_original_size)\n",
    "    \n",
    "    y_test = testing_labels_encoded \n",
    "    y_val = validation_labels_encoded\n",
    "    \n",
    "    X_train_wav = []\n",
    "    X_test_wav = []\n",
    "    X_val_wav = []\n",
    "    \n",
    "\n",
    "    \n",
    "    for i in tqdm(range(Training_size)):\n",
    "        try: \n",
    "            fs, train_sample_wav = wavfile.read(os.path.join(dataset_path, X_training_audio_dataset_paths[i]))\n",
    "        except ValueError:\n",
    "            print(os.path.join(dataset_path, X_training_audio_dataset_paths[i]))\n",
    "            pass\n",
    "            \n",
    "        _dummy_sample_wav = train_sample_wav.copy() # get copy of wav file that you can modify\n",
    "        _dummy_sample_wav.resize(adjusted_sample_length)\n",
    "        _dummy_sample_wav = _dummy_sample_wav.reshape(-1, segmentLength)\n",
    "        X_train_wav.append(_dummy_sample_wav.astype(np.float32))\n",
    "\n",
    "        \n",
    "        \n",
    "    for i in tqdm(range(len(X_testing_audio_dataset_paths))):\n",
    "        fs, test_sample_wav = wavfile.read(os.path.join(dataset_path, X_testing_audio_dataset_paths[i]))\n",
    "        _dummy_sample_wav = test_sample_wav.copy()\n",
    "        _dummy_sample_wav.resize(adjusted_sample_length)\n",
    "        _dummy_sample_wav = _dummy_sample_wav.reshape(-1, segmentLength)\n",
    "        X_test_wav.append(_dummy_sample_wav.astype(np.float32))\n",
    "        \n",
    "        \n",
    "    for i in tqdm(range(len(X_validation_audio_dataset_paths))):\n",
    "        fs, val_sample_wav = wavfile.read(os.path.join(dataset_path, X_validation_audio_dataset_paths[i]))\n",
    "        _dummy_sample_wav = val_sample_wav.copy()\n",
    "        _dummy_sample_wav.resize(adjusted_sample_length)\n",
    "        _dummy_sample_wav = _dummy_sample_wav.reshape(-1, segmentLength)\n",
    "        X_val_wav.append(_dummy_sample_wav.astype(np.float32))\n",
    "        \n",
    "        \n",
    "    return X_train_wav, X_test_wav, X_val_wav, y_train, y_test, y_val\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mfccs(samples, fs, upper_edge_hz, lower_edge_hz, num_mel_bins, num_mfcc):\n",
    "    frame_length = 1024\n",
    "    stfts = tf.signal.stft(samples, frame_length=frame_length, frame_step=frame_length, fft_length=frame_length) # no overlap\n",
    "    spectrograms = tf.abs(stfts)\n",
    "    spectrograms = tf.reshape(spectrograms, (spectrograms.shape[0],spectrograms.shape[1],-1))\n",
    "    num_spectrogram_bins = stfts.shape[-1]\n",
    "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(num_mel_bins, num_spectrogram_bins, fs, lower_edge_hz, upper_edge_hz)\n",
    "    mel_spectrograms = tf.tensordot(spectrograms, linear_to_mel_weight_matrix, 1)\n",
    "    log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
    "    mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrograms)[..., :num_mfcc]\n",
    "    return tf.reshape(mfccs, (mfccs.shape[0],mfccs.shape[1],mfccs.shape[2],-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Creation of Text Files containing Samples for Training, Testing and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "global dataset_path\n",
    "dataset_path = os.path.join(\"speech_commands_v0.02\")\n",
    "training_dataset_path = os.path.join(dataset_path, \"training_list.txt\")\n",
    "testing_dataset_path = os.path.join(dataset_path, \"testing_list.txt\")\n",
    "validation_dataset_path = os.path.join(dataset_path, \"validation_list.txt\")\n",
    "if not os.path.exists(training_dataset_path):\n",
    "    create_training_txt_file(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11005\n",
      "84849\n",
      "9981\n"
     ]
    }
   ],
   "source": [
    "testing_labels = get_labels(testing_dataset_path)\n",
    "print(len(testing_labels))\n",
    "training_labels = get_labels(training_dataset_path)\n",
    "print(len(training_labels))\n",
    "validation_labels = get_labels(validation_dataset_path)\n",
    "print(len(validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal Encoding of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_background_noise_' 'backward' 'bed' 'bird' 'cat' 'dog' 'down' 'eight'\n",
      " 'five' 'follow' 'forward' 'four' 'go' 'happy' 'house' 'learn' 'left'\n",
      " 'marvin' 'nine' 'no' 'off' 'on' 'one' 'right' 'seven' 'sheila' 'six'\n",
      " 'stop' 'three' 'tree' 'two' 'up' 'visual' 'wow' 'yes' 'zero']\n"
     ]
    }
   ],
   "source": [
    "training_encoder = LabelEncoder()\n",
    "training_encoder.fit(training_labels)\n",
    "training_labels_encoded = training_encoder.transform(training_labels)\n",
    "\n",
    "# training_encoder.fit(testing_labels)\n",
    "testing_labels_encoded = training_encoder.transform(testing_labels)\n",
    "\n",
    "validation_labels_encoded = training_encoder.transform(validation_labels)\n",
    "\n",
    "\n",
    "print(training_encoder.classes_)\n",
    "\n",
    "# sanity check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Getting an idea of class counts in Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Counter({'zero': 3250, 'five': 3240, 'yes': 3228, 'seven': 3205, 'nine': 3170, 'one': 3140, 'down': 3134, 'no': 3130, 'stop': 3111, 'two': 3111, 'go': 3106, 'six': 3088, 'on': 3086, 'left': 3037, 'eight': 3033, 'right': 3019, 'off': 2970, 'three': 2966, 'four': 2955, 'up': 2948, 'house': 1727, 'wow': 1724, 'dog': 1711, 'marvin': 1710, 'bird': 1697, 'cat': 1657, 'happy': 1632, 'sheila': 1606, 'bed': 1594, 'tree': 1407, 'backward': 1346, 'visual': 1288, 'learn': 1286, 'follow': 1275, 'forward': 1256, '_background_noise_': 6})\n",
      "\n",
      "Testing: Counter({'five': 445, 'up': 425, 'two': 424, 'yes': 419, 'zero': 418, 'left': 412, 'stop': 411, 'eight': 408, 'nine': 408, 'seven': 406, 'down': 406, 'no': 405, 'three': 405, 'go': 402, 'off': 402, 'four': 400, 'one': 399, 'right': 396, 'on': 396, 'six': 394, 'dog': 220, 'sheila': 212, 'bed': 207, 'wow': 206, 'happy': 203, 'marvin': 195, 'cat': 194, 'tree': 193, 'house': 191, 'bird': 185, 'follow': 172, 'backward': 165, 'visual': 165, 'learn': 161, 'forward': 155})\n",
      "\n",
      "Validation: Counter({'no': 406, 'yes': 397, 'seven': 387, 'zero': 384, 'six': 378, 'down': 377, 'off': 373, 'four': 373, 'go': 372, 'five': 367, 'right': 363, 'on': 363, 'nine': 356, 'three': 356, 'left': 352, 'one': 351, 'stop': 350, 'up': 350, 'eight': 346, 'two': 345, 'happy': 219, 'bed': 213, 'sheila': 204, 'dog': 197, 'marvin': 195, 'house': 195, 'wow': 193, 'bird': 182, 'cat': 180, 'tree': 159, 'backward': 153, 'forward': 146, 'visual': 139, 'follow': 132, 'learn': 128})\n",
      "\n",
      " Counter({35: 3250, 8: 3240, 34: 3228, 24: 3205, 18: 3170, 22: 3140, 6: 3134, 19: 3130, 27: 3111, 30: 3111, 12: 3106, 26: 3088, 21: 3086, 16: 3037, 7: 3033, 23: 3019, 20: 2970, 28: 2966, 11: 2955, 31: 2948, 14: 1727, 33: 1724, 5: 1711, 17: 1710, 3: 1697, 4: 1657, 13: 1632, 25: 1606, 2: 1594, 29: 1407, 1: 1346, 32: 1288, 15: 1286, 9: 1275, 10: 1256, 0: 6})\n",
      "\n",
      " Counter({8: 445, 31: 425, 30: 424, 34: 419, 35: 418, 16: 412, 27: 411, 7: 408, 18: 408, 24: 406, 6: 406, 19: 405, 28: 405, 12: 402, 20: 402, 11: 400, 22: 399, 23: 396, 21: 396, 26: 394, 5: 220, 25: 212, 2: 207, 33: 206, 13: 203, 17: 195, 4: 194, 29: 193, 14: 191, 3: 185, 9: 172, 1: 165, 32: 165, 15: 161, 10: 155})\n"
     ]
    }
   ],
   "source": [
    "print(\"Training:\", Counter(training_labels))\n",
    "print(\"\\nTesting:\", Counter(testing_labels))\n",
    "print(\"\\nValidation:\", Counter(validation_labels))\n",
    "\n",
    "print(\"\\n\",Counter(training_labels_encoded))\n",
    "print(\"\\n\",Counter(testing_labels_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Processing Pipeline on WAV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little bit about the audio files at hand:\n",
    "- We have a total of 105 829 audio files split in the following way for Training, Testing and Validation:\n",
    "    - Training: 84850\n",
    "    - Testing: 11005\n",
    "    - Validation: 9981\n",
    "- Each audio file was sampled at a 16000 Hz rate and each file is *trimmed down to one second length*. Thus per audio file, you can expect 16000 samples of information describing that file.\n",
    "- The breakdown of classes found in each set is as follows:\n",
    "    - Training Set: '_background_noise_','backward','bed','bird','cat','dog','down','eight','five','follow','forward','four','go','happy','house','learn','left','marvin','nine','no','off','on','one','right','seven','sheila','six','stop','three','tree','two' 'up','visual','wow','yes','zero'.\n",
    "    - Testing Set: 'backward','bed','bird','cat','dog','down','eight','five','follow','forward','four','go','happy','house','learn','left','marvin','nine','no','off','on','one','right','seven','sheila','six','stop','three','tree','two' 'up','visual','wow','yes','zero'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 42203/80000 [02:04<02:43, 230.49it/s]/usr/local/lib/python3.7/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n",
      "100%|██████████| 80000/80000 [04:20<00:00, 307.14it/s]\n",
      "100%|██████████| 11005/11005 [00:29<00:00, 374.66it/s]\n",
      "100%|██████████| 9981/9981 [00:34<00:00, 285.35it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = load_audio_data(training_dataset_path, training_labels_encoded, testing_dataset_path, testing_labels_encoded, validation_dataset_path, validation_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC extraction time: 386.0386219024658 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "X_train_mfccs = compute_mfccs(X_train, fs = 16000, upper_edge_hz = 8000.0, lower_edge_hz = 60.0, num_mel_bins = 80, num_mfcc = 13)\n",
    "end = time.time()\n",
    "print(\"MFCC extraction time:\", end-start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC extraction time: 35.83346199989319 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "X_test_mfccs = compute_mfccs(X_test, fs = 16000, upper_edge_hz = 8000.0, lower_edge_hz = 60.0, num_mel_bins = 80, num_mfcc = 13)\n",
    "end = time.time()\n",
    "print(\"MFCC extraction time:\", end-start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC extraction time: 32.01011300086975 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "X_val_mfccs = compute_mfccs(X_val, fs = 16000, upper_edge_hz = 8000.0, lower_edge_hz = 60.0, num_mel_bins = 80, num_mfcc = 13)\n",
    "end = time.time()\n",
    "print(\"MFCC extraction time:\", end-start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (80000, 15, 13, 1)\n",
      "X_test shape: (11005, 15, 13, 1)\n",
      "X_val shape: (9981, 15, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train_mfccs.shape)\n",
    "print(\"X_test shape:\", X_test_mfccs.shape)\n",
    "print(\"X_val shape:\", X_val_mfccs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initiation of Conv Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 80000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 100\n",
    "\n",
    "train_set = X_train_mfccs # normalize to mean 0.5 and variance = 0\n",
    "train_labels = y_train\n",
    "print(len(train_set), len(train_labels))\n",
    "\n",
    "\n",
    "test_set = X_test_mfccs # normalize to mean 0.5 and variance = 0\n",
    "test_labels = y_test\n",
    "\n",
    "val_set = X_val_mfccs\n",
    "val_labels = y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 9981 samples\n",
      "Epoch 1/100\n",
      "80000/80000 [==============================] - 49s 616us/sample - loss: 1.7338 - accuracy: 0.4940 - val_loss: 1.7554 - val_accuracy: 0.5243\n",
      "Epoch 2/100\n",
      "16288/80000 [=====>........................] - ETA: 35s - loss: 1.1145 - accuracy: 0.6675"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(layers.InputLayer(input_shape=(train_set.shape[1],train_set.shape[2],train_set.shape[3]), batch_size= batch_size))\n",
    "model.add(layers.Conv2D(filters=3,kernel_size=(5,5),padding=\"same\",input_shape=(train_set[0].shape)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Conv2D(filters=16,kernel_size=(5,5),padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.MaxPool2D((3,3)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=32,kernel_size=(5,5),padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.MaxPool2D((4,4)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=48,kernel_size=(5,5),padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(48))\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Dense(36))\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "model.fit(train_set, train_labels, batch_size, epochs, validation_data=(val_set, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_set, test_labels, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"First_it.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion of Model from .h file to TFLite file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the helper functions from the Week 6 lab dealing with MFCC coefficients, we complete the conversion process as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert tensor types to numpy types prior to conversion\n",
    "\"\"\"\n",
    "def check_correct_type(input_set):\n",
    "    assert type(input_set) == np.ndarray, f\"Wrong type. Your set is of type {type(input_set)} when it should be np.ndarray\"\n",
    "check_correct_type(train_labels)\n",
    "check_correct_type(train_set.numpy())\n",
    "check_correct_type(test_set)\n",
    "check_correct_type(test_labels)\n",
    "\n",
    "train_set = train_set.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"First_it\" #name given to h5 file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_converter(model, train_set: np.ndarray, representative_dataset_size: int, model_name: str):\n",
    "    \"\"\"\n",
    "Model conversion function derived from Week 6 lab to convert Keras model to TFLite, which\n",
    "quantizes the weights of our model using 8-bit integer quantization.\n",
    "\n",
    "Parameters:\n",
    "    model: trained Keras model contained in .h5 file\n",
    "    training_set: training set used to train Keras model\n",
    "    representative_dataset_size: Integer value representing size of subset of dataset used to train \n",
    "        our model. It should only be a value around a few hundred as it only serves \"to calibrate or estimate the range, \n",
    "        of floating-point arrays in the model (such as model input, activation outputs of intermediate layers, and model output) \n",
    "        for quantization.\" (TFLite Documentation)\n",
    "    h5_file_name: string value denoting the name of the file on which the Keras Model is persisted.\n",
    "    \n",
    "Outputs:\n",
    "    No output as a result of this function call. New file created and persisted containing quantized\n",
    "    model. Has '.tflite' extension.\n",
    "\"\"\"\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model) # Convert the model to the TensorFlow Lite format with quantization\n",
    "    quantize = True\n",
    "    if (quantize):\n",
    "        def representative_dataset():\n",
    "            for i in range(representative_dataset_size):\n",
    "                yield([train_set[i].reshape(1,15,13,1)])\n",
    "        # Set the optimization flag.\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        # Enforce full-int8 quantization\n",
    "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "        converter.inference_input_type = tf.int16  # or tf.uint8\n",
    "        converter.inference_output_type = tf.int16  # or tf.uint8\n",
    "        # Provide a representative dataset to ensure we quantize correctly.\n",
    "    converter.representative_dataset = representative_dataset\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    open(h5_file_name + '.tflite', 'wb').write(tflite_model)\n",
    "    return tflite_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_c_array(quantized_model, model_name):\n",
    "    \"\"\"\n",
    "Lab Week 6 Function: Convert some hex value into an array for C programming.\n",
    "Then write TFLite model to a C source (or header) file to be used on Cube AI platform.\n",
    "\n",
    "Parameters:\n",
    "    quantized model: contains weights quantized to 8 bit fixed-point representations.\n",
    "    model_name: name of tflite model.  \n",
    "    \n",
    "    \"\"\"\n",
    "    c_str = ''\n",
    "\n",
    "    # Create header guard\n",
    "    c_str += '#ifndef ' + model_name.upper() + '_H\\n'\n",
    "    c_str += '#define ' + model_name.upper() + '_H\\n\\n'\n",
    "\n",
    "    # Add array length at top of file\n",
    "    c_str += '\\nunsigned int ' + model_name + '_len = ' + str(len(quantized_model)) + ';\\n'\n",
    "\n",
    "    # Declare C variable\n",
    "    c_str += 'unsigned char ' + model_name + '[] = {'\n",
    "    hex_array = []\n",
    "    for i, val in enumerate(quantized_model) :\n",
    "\n",
    "        # Construct string from hex\n",
    "        hex_str = format(val, '#04x')\n",
    "\n",
    "        # Add formatting so each line stays within 80 characters\n",
    "        if (i + 1) < len(quantized_model):\n",
    "            hex_str += ','\n",
    "        if (i + 1) % 12 == 0:\n",
    "            hex_str += '\\n '\n",
    "        hex_array.append(hex_str)\n",
    "\n",
    "    # Add closing brace\n",
    "    c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
    "    #print(c_str)\n",
    "\n",
    "    # Close out header guard\n",
    "    c_str += '#endif //' + model_name.upper() + '_H'\n",
    "    with open(model_name + '.h', 'w') as file:\n",
    "        file.write(c_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = model_converter(model, train_set, 1000, model_name)\n",
    "hex_to_c_array(quantized_model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantized_model_comparison(original_score, quantized_model, test_set, test_labels):\n",
    "    \"\"\"\n",
    "Function inspired from Lab Week 6 to compute quality of network after quantization. \n",
    "    \"\"\"\n",
    "    tflite_interpreter = tf.lite.Interpreter(model_content=quantized_model)\n",
    "    tflite_interpreter.allocate_tensors()\n",
    "    input_details = tflite_interpreter.get_input_details()\n",
    "    output_details = tflite_interpreter.get_output_details()\n",
    "    print(\"== Input details ==\")\n",
    "    print(\"\\n\\n\",input_details)\n",
    "    print(\"name:\", input_details[0]['name'])\n",
    "    print(\"shape:\", input_details[0]['shape'])\n",
    "    print(\"type:\", input_details[0]['dtype'])\n",
    "\n",
    "    print(\"\\n== Output details ==\")\n",
    "    print(\"name:\", output_details[0]['name'])\n",
    "    print(\"shape:\", output_details[0]['shape'])\n",
    "    print(\"type:\", output_details[0]['dtype'])\n",
    "    \n",
    "    \n",
    "    predictions = np.zeros((len(test_set),), dtype=int)\n",
    "    input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "    for i in range(len(test_set)):\n",
    "        val_batch = test_set[i]\n",
    "        val_batch = val_batch / input_scale + input_zero_point\n",
    "        val_batch = np.expand_dims(val_batch, axis=0).astype(input_details[0][\"dtype\"])\n",
    "        tflite_interpreter.set_tensor(input_details[0]['index'], val_batch)\n",
    "        tflite_interpreter.allocate_tensors()\n",
    "        tflite_interpreter.invoke()\n",
    "\n",
    "        tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "        #print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
    "        output = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "        predictions[i] = output.argmax()\n",
    "        \n",
    "    sum = 0\n",
    "    for i in tqdm(range(len(predictions))):\n",
    "        if (predictions[i] == test_labels[i]):\n",
    "            sum = sum + 1\n",
    "    accuracy_score = sum / len(predictions)\n",
    "    print(\"Accuracy of quantized to int8 model is {}%\".format(accuracy_score*100))\n",
    "    print(\"Compared to float32 accuracy of {}%\".format(score[1]*100))\n",
    "    print(\"We have a change of {}%\".format((accuracy_score-score[1])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Input details ==\n",
      "\n",
      "\n",
      " [{'name': 'input_8', 'index': 24, 'shape': array([ 1, 15, 13,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}]\n",
      "name: input_8\n",
      "shape: [ 1 15 13  1]\n",
      "type: <class 'numpy.float32'>\n",
      "\n",
      "== Output details ==\n",
      "name: Identity\n",
      "shape: [ 1 36]\n",
      "type: <class 'numpy.float32'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in true_divide\n",
      "100%|██████████| 11005/11005 [00:00<00:00, 1846184.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of quantized to int8 model is 3.6347114947751025%\n",
      "Compared to float32 accuracy of 65.62471389770508%\n",
      "We have a change of -61.990002402929974%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "quantized_model_comparison(score, quantized_model, test_set, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ML_on_MCU_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
